{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIALIZE REQUIREMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# !pip install python-dotenv\n",
    "# load_dotenv()\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "import os, glob, warnings, datacube, rasterio, folium, json\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as rio\n",
    "import pandas as pd\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "\n",
    "from scipy.ndimage import uniform_filter\n",
    "from scipy.ndimage import variance\n",
    "from skimage.filters import threshold_minimum\n",
    "from datacube.utils.geometry import Geometry\n",
    "\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.plotting import display_map, rgb\n",
    "from deafrica_tools.areaofinterest import define_area\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local modules\n",
    "from tools.gdrive import GDrive\n",
    "\n",
    "gd = GDrive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/a.DEA/dea-raster-builder/tools/gdrive.py:151\u001b[0m, in \u001b[0;36mGDrive.get_storage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_storage\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    Gets Google drive storage information.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m    storage_df: pd.DataFrame\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorageQuota\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoogle Drive Storage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    154\u001b[0m     cap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(storage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorageQuota\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m9\u001b[39m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/googleapiclient/http.py:923\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody))\n\u001b[1;32m    922\u001b[0m \u001b[38;5;66;03m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[0;32m--> 923\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_callbacks:\n\u001b[1;32m    936\u001b[0m     callback(resp)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/googleapiclient/http.py:222\u001b[0m, in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retry_num \u001b[38;5;241m==\u001b[39m num_retries:\n\u001b[0;32m--> 222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/googleapiclient/http.py:191\u001b[0m, in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     resp, content \u001b[38;5;241m=\u001b[39m \u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _ssl_SSLError \u001b[38;5;28;01mas\u001b[39;00m ssl_error:\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/google_auth_httplib2.py:218\u001b[0m, in \u001b[0;36mAuthorizedHttp.request\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     body_stream_position \u001b[38;5;241m=\u001b[39m body\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# Make the request.\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m response, content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mredirections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mredirections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    234\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh_status_codes\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m _credential_refresh_attempt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_refresh_attempts\n\u001b[1;32m    236\u001b[0m ):\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/httplib2/__init__.py:1724\u001b[0m, in \u001b[0;36mHttp.request\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m   1722\u001b[0m             content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1724\u001b[0m             (response, content) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthority\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredirections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcachekey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1728\u001b[0m     is_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(e, socket\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/httplib2/__init__.py:1444\u001b[0m, in \u001b[0;36mHttp._request\u001b[0;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth:\n\u001b[1;32m   1442\u001b[0m     auth\u001b[38;5;241m.\u001b[39mrequest(method, request_uri, headers, body)\n\u001b[0;32m-> 1444\u001b[0m (response, content) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth:\n\u001b[1;32m   1447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m auth\u001b[38;5;241m.\u001b[39mresponse(response, body):\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/httplib2/__init__.py:1366\u001b[0m, in \u001b[0;36mHttp._conn_request\u001b[0;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1366\u001b[0m         \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1367\u001b[0m     conn\u001b[38;5;241m.\u001b[39mrequest(method, request_uri, body, headers)\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mtimeout:\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/httplib2/__init__.py:1156\u001b[0m, in \u001b[0;36mHTTPSConnectionWithTimeout.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_timeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout):\n\u001b[1;32m   1155\u001b[0m     sock\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout)\n\u001b[0;32m-> 1156\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mwrap_socket(sock, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost)\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;66;03m# Python 3.3 compatibility: emulate the check_hostname behavior\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: timed out"
     ]
    }
   ],
   "source": [
    "gd.get_storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "\n",
    "Connect to the datacube so we can access DEA data.\n",
    "The `app` parameter is a unique name for the analysis which is based on the notebook file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"Radar_water_detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G-Drive Folder IDs and Timerange Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder ids by copying the ID from the g-drive folder url\n",
    "# TEST/\n",
    "F_MN_FID = \"1KBig_UZLT0fgFXsACMHQTb7c_Poao-wh\"\n",
    "F_MD_FID = \"1dWde-mzh8Sc9BIEMNUByq7Z6Yags0JZh\"\n",
    "\n",
    "PRF_MN_FID = \"1MVAMwv0E3sZ6qK8E93MlnGcPTr6yXge4\"\n",
    "PRF_MD_FID = \"1oROFY5hKi3w7pbkrCnHtGLIJT_nBraog\"\n",
    "\n",
    "POF_MN_FID = None\n",
    "POF_MD_FID = None\n",
    "\n",
    "FE_MN_FID = \"1RpE2-Pe-KihKdCk0TKLvTzZgrv5QGOeu\"\n",
    "FE_MD_FID = \"1KDTiwmmdaV5LBh6Dj1qAB5KTRNQu_-Xq\"\n",
    "\n",
    "MF_MX_FID = \"100Xf41aDRLwZHiPxXzSMHbiCh4JWosaD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main time period of analysis\n",
    "timerange = (\"2023-11\", \"2024-11\")\n",
    "\n",
    "# Define sub-periods of analysis - should be within main time period\n",
    "pre_flood = [\"2024-02\", \"2024-03\", \"2024-04\"]\n",
    "flood = [\"2024-05\", \"2024-06\", \"2024-07\", \"2024-08\", \"2024-09\"]\n",
    "post_flood = []\n",
    "max_flood = [\"2023-11\", \"2024-11\"]\n",
    "\n",
    "# Run 1. aoi-threshold.ipynb to get the value of th_aoi and store it here.\n",
    "th_aoi = -27.395682"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter and Classifier Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply lee filtering on S1 image. Speckle Filter\n",
    "def lee_filter(da, size):\n",
    "    \"\"\"\n",
    "    Apply lee filter of specified window size.\n",
    "    Adapted from https://stackoverflow.com/questions/39785970/speckle-lee-filter-in-python\n",
    "\n",
    "    \"\"\"\n",
    "    img = da.values\n",
    "    img_mean = uniform_filter(img, size)\n",
    "    img_sqr_mean = uniform_filter(img**2, size)\n",
    "    img_variance = img_sqr_mean - img_mean**2\n",
    "\n",
    "    overall_variance = variance(img)\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance)\n",
    "    img_output = img_mean + img_weights * (img - img_mean)\n",
    "\n",
    "    return img_output\n",
    "\n",
    "\n",
    "# Classifier Function\n",
    "def S1_water_classifier(da, threshold):\n",
    "    water_data_array = da < threshold\n",
    "    return water_data_array.to_dataset(name=\"s1_water\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operational Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate raster outputs\n",
    "def gen_output(\n",
    "    DS: xr.DataArray,\n",
    "    i: list,\n",
    "    poly: Geometry,\n",
    "    cell: int,\n",
    "    aoi_m: list,\n",
    "    period: Literal[\"preflood\", \"flood\", \"postflood\", \"flood_extents\", \"maxflood\"],\n",
    "    measure: Literal[\"mean\", \"median\", \"max\"],\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Generates file names and uploads tp Google Drive\n",
    "\n",
    "    Parameters:\n",
    "    DS: xr.DataArray, required\n",
    "        Dataset to be converted into raster output.\n",
    "    i: list, required\n",
    "        Index of centroid list.\n",
    "    poly: Geometry, required\n",
    "        Polygon feature used to create the DS.\n",
    "    cell: int, required\n",
    "        Cell number being processed.\n",
    "    aoi_m: list, required\n",
    "        List of geojson feature collection (cells) that make up the entire grid.\n",
    "    period: Literal[\"preflood\", \"flood\", \"postflood\", \"flood_extents\"], required\n",
    "        Time period of the process - PRE_FLOOD, FLOOD.\n",
    "    measure: Literal[\"mean\", \"median\"], required\n",
    "        Central tendency measurement of the DS - mean, median.\n",
    "\n",
    "    Returns:\n",
    "    err: list\n",
    "        Error log list of [x, y, cell_id and None]. None will store the error \"P\" - Processing or \"U\" - Upload.\n",
    "    \"\"\"\n",
    "\n",
    "    err = []\n",
    "\n",
    "    pm_dict = {\n",
    "        \"preflood_mean\": [pre_flood, PRF_MN_FID],\n",
    "        \"preflood_median\": [pre_flood, PRF_MD_FID],\n",
    "        \"flood_mean\": [flood, F_MN_FID],\n",
    "        \"flood_median\": [flood, F_MD_FID],\n",
    "        \"postflood_mean\": [post_flood, POF_MN_FID],\n",
    "        \"postflood_median\": [post_flood, POF_MD_FID],\n",
    "        \"flood_extents_mean\": [timerange, FE_MN_FID],\n",
    "        \"flood_extents_median\": [timerange, FE_MD_FID],\n",
    "        \"maxflood_max\":[timerange, MF_MX_FID]\n",
    "    }\n",
    "\n",
    "    poly_gdf = gpd.GeoDataFrame(geometry=[poly], crs=poly.crs)\n",
    "    lat_range = (poly_gdf.total_bounds[1], poly_gdf.total_bounds[3])\n",
    "    lon_range = (poly_gdf.total_bounds[0], poly_gdf.total_bounds[2])\n",
    "    g = poly_gdf.centroid\n",
    "\n",
    "    data_val = \"CELL_\" + str(i[2]) + \"_{}_{}\".format(period.upper(), measure.upper())\n",
    "    data_name = data_val + \".tif\"\n",
    "    data_out = \"output/{}/\".format(period) + data_name\n",
    "    DS.rio.to_raster(data_out)\n",
    "\n",
    "    # preflood meta\n",
    "    data_dict = {\n",
    "        \"GRID_CELL_ID\": i[2],\n",
    "        \"start_time\": pm_dict[\"{}_{}\".format(period, measure)][0][0],  # pre_flood[0]\n",
    "        \"end_time\": pm_dict[\"{}_{}\".format(period, measure)][0][-1],  # pre_flood[-1]\n",
    "        \"lat\": lat_range,\n",
    "        \"lon\": lon_range,\n",
    "        \"centroid\": \"{}, {}\".format(g.y[0], g.x[0]),\n",
    "        \"crs\": str(poly.crs),\n",
    "    }\n",
    "\n",
    "    text_flie_name = data_val + \"_META.json\"\n",
    "    data_meta_path = \"output/{}/\".format(period) + text_flie_name\n",
    "    with open(data_meta_path, \"w\") as f:\n",
    "        json.dump(data_dict, f)\n",
    "\n",
    "    try:\n",
    "        gd.upload_files(\n",
    "            [data_out, data_meta_path], pm_dict[\"{}_{}\".format(period, measure)][1]\n",
    "        )  # pm_dict['preflood_mean'][1] = FOLDER_ID\n",
    "    except Exception as e:\n",
    "        err.append([g.x[0], g.y[0], i[2], \"U-PRF\"])\n",
    "        print(\n",
    "            \"\\n\\n\"\n",
    "            + \"\\033[31m\"\n",
    "            + \"ERROR UPLOADING GRID CELL ID {} NO.  {}/{} CENTROID ({}, {}). LOGGED CENTROID INFO in e_log\".format(\n",
    "                i[2], cell, len(aoi_m), round(g.y[0], 5), round(g.x[0], 5)\n",
    "            )\n",
    "            + \"\\033[0m\"\n",
    "        )\n",
    "        print(\"UPLOAD ERROR: {}\".format(e))\n",
    "\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_elog(e_log: list) -> list:\n",
    "    \"\"\"\n",
    "    Writes a the error log json file and uploads it to the google drive folder ID, if specified.\n",
    "\n",
    "    Parameters:\n",
    "    e_log: list, required\n",
    "        Error log list of [x, y, cell_id and None]. None will store the error \"P\" - Processing or \"U\" - Upload.\n",
    "\n",
    "    Returns:\n",
    "    e_log: list\n",
    "        Error log list having the same values as the input parameter\n",
    "    \"\"\"\n",
    "    e_log = np.array(e_log)\n",
    "    with open(\"error_centroids.json\", \"w\") as filehandle:\n",
    "        json.dump(e_log.tolist(), filehandle)\n",
    "\n",
    "    # read error log from disk\n",
    "    with open(\"error_centroids.json\") as f:\n",
    "        e_log = json.load(f)\n",
    "    for e in e_log:\n",
    "        e[0] = float(e[0])\n",
    "        e[1] = float(e[1])\n",
    "        e[2] = int(e[2])\n",
    "\n",
    "    try:\n",
    "        gd.upload_files([\"error_centroids.json\"], ERR_FOLDER_ID, False)\n",
    "    except Exception as e:\n",
    "        print(\"FAILED TO UPLOAD ERROR LOG FILE REASON:{}\".format(e))\n",
    "\n",
    "    return e_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the input grid\n",
    "def iterate_grid(aoi_m: list, c: list) -> list:\n",
    "    \"\"\"\n",
    "    Iterates through every feature (cell) in the AOI grid.\n",
    "\n",
    "    Parameters:\n",
    "    aoi_m: list, required\n",
    "        List of geojson feature collection (cells) that make up the entire grid.\n",
    "    c: list, required\n",
    "        List of [x, y, cell_id and None]. None will store the error \"P\" - Processing or \"U\" - Upload, if executio fails\n",
    "\n",
    "    Returns:\n",
    "    e_log: list\n",
    "        Error log list of [x, y, cell_id and None]. None will store the error \"P\" - Processing or \"U\" - Upload.\n",
    "    \"\"\"\n",
    "\n",
    "    e_log = []\n",
    "    cell = 1\n",
    "    for aoi, i in zip(aoi_m, c):\n",
    "        geopolygon = Geometry(aoi[\"features\"][0][\"geometry\"], crs=\"epsg:4326\")\n",
    "        geopolygon_gdf = gpd.GeoDataFrame(geometry=[geopolygon], crs=geopolygon.crs)\n",
    "        g = geopolygon_gdf.centroid\n",
    "        print(\n",
    "            \"\\n\\n\"\n",
    "            + \"\\033[32m\"\n",
    "            + \"PROCESSING GRID CELL ID {} NO. {}/{} CENTROID ({}, {})\".format(\n",
    "                i[2], cell, len(aoi_m), round(g.y[0], 5), round(g.x[0], 5)\n",
    "            )\n",
    "            + \"\\033[0m\"\n",
    "        )\n",
    "\n",
    "        # Get the latitude and longitude range of the geopolygon\n",
    "        lat_range = (geopolygon_gdf.total_bounds[1], geopolygon_gdf.total_bounds[3])\n",
    "        lon_range = (geopolygon_gdf.total_bounds[0], geopolygon_gdf.total_bounds[2])\n",
    "\n",
    "        # Load Sentinel1 data\n",
    "        try:\n",
    "            S1 = load_ard(\n",
    "                dc=dc,\n",
    "                products=[\"s1_rtc\"],\n",
    "                # measurements=[\"vv\", \"vh\"],\n",
    "                measurements=[\"vh\"],\n",
    "                y=lat_range,\n",
    "                x=lon_range,\n",
    "                time=timerange,\n",
    "                output_crs=\"EPSG:6933\",\n",
    "                resolution=(-20, 20),\n",
    "                group_by=\"solar_day\",\n",
    "                dtype=\"native\",\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Log error aoi centroids and keep looping\n",
    "            e_log.append([g.x[0], g.y[0], i[2], \"P\"])\n",
    "            print(\n",
    "                \"\\n\\n\"\n",
    "                + \"\\033[31m\"\n",
    "                + \"ERROR PROCESSING GRID CELL {}/{} CENTROID ({}, {}). LOGGED CENTROID INFO in e_log\".format(\n",
    "                    i[2], len(aoi_m), round(g.y[0], 5), round(g.x[0], 5)\n",
    "                )\n",
    "                + \"\\033[0m\"\n",
    "            )\n",
    "            print(\"PROCESS ERROR: {}\".format(e))\n",
    "            cell += 1\n",
    "            continue\n",
    "\n",
    "        # timesteps = [2, 4, 6, 9, 11]\n",
    "\n",
    "        # The lee filter above doesn't handle null values\n",
    "        # We therefore set null values to 0 before applying the filter\n",
    "        valid = np.isfinite(S1)\n",
    "        S1 = S1.where(valid, 0)\n",
    "\n",
    "        # Create a new entry in dataset corresponding to filtered VV and VH data\n",
    "        S1[\"filtered_vh\"] = S1.vh.groupby(\"time\").apply(lee_filter, size=7)\n",
    "\n",
    "        # Null pixels should remain null\n",
    "        S1[\"filtered_vh\"] = S1.filtered_vh.where(valid.vh)\n",
    "\n",
    "        # Convert the digital numbers to dB\n",
    "        S1[\"filtered_vh\"] = 10 * np.log10(S1.filtered_vh)\n",
    "\n",
    "        threshold_vh = th_aoi\n",
    "\n",
    "        S1[\"water\"] = S1_water_classifier(S1.filtered_vh, threshold_vh).s1_water\n",
    "        S1Water = S1.water\n",
    "        S1_BIN = S1Water.where(S1Water > 0)\n",
    "        FS1 = S1_BIN\n",
    "        PRFS1 = S1_BIN\n",
    "\n",
    "        # Creating outputs\n",
    "        # Export to raster - upload to g-drive - delete from sandbox\n",
    "\n",
    "        print(\"Uploading...\")\n",
    "        # -------------- maxflood ----------------\n",
    "        if i[3] in [None, \"P\", \"U-PRF\"]:\n",
    "            S1_MX = S1_BIN.sel(time=max_flood, method=\"nearest\").max(dim='time')\n",
    "            err = gen_output(\n",
    "                S1_MX, i, geopolygon, cell, aoi_m, \"maxflood\", \"max\"\n",
    "            )\n",
    "\n",
    "        \n",
    "        # # -------------- preflood ----------------\n",
    "        # if i[3] in [None, \"P\", \"U-PRF\"]:\n",
    "        #     S1_PRF_MD = PRFS1.sel(time=pre_flood, method=\"nearest\").median(dim=\"time\")\n",
    "        #     S1_PRF_MN = PRFS1.sel(time=pre_flood, method=\"nearest\").mean(dim=\"time\")\n",
    "        #     err = gen_output(\n",
    "        #         S1_PRF_MD, i, geopolygon, cell, aoi_m, \"preflood\", \"median\"\n",
    "        #     )\n",
    "        #     if len(err) > 0:\n",
    "        #         e_log.extend(err)\n",
    "        #     err = gen_output(S1_PRF_MN, i, geopolygon, cell, aoi_m, \"preflood\", \"mean\")\n",
    "        #     if len(err) > 0:\n",
    "        #         e_log.extend(err)\n",
    "\n",
    "        # # --------------- flood ------------------\n",
    "        # if i[3] in [None, \"P\", \"U-F\"]:\n",
    "        #     S1_F_MD = FS1.sel(time=flood, method=\"nearest\").median(dim=\"time\")\n",
    "        #     S1_F_MN = FS1.sel(time=flood, method=\"nearest\").mean(dim=\"time\")\n",
    "        #     err = gen_output(S1_F_MD, i, geopolygon, cell, aoi_m, \"flood\", \"median\")\n",
    "        #     if len(err) > 0:\n",
    "        #         e_log.extend(err)\n",
    "        #     err = gen_output(S1_F_MN, i, geopolygon, cell, aoi_m, \"flood\", \"mean\")\n",
    "        #     if len(err) > 0:\n",
    "        #         e_log.extend(err)\n",
    "\n",
    "        # # ------------ flood-extents --------------\n",
    "        # if i[3] in [None, \"P\", \"U-FE\"]:\n",
    "        #     S1_FE_MD = S1_F_MD - S1_PRF_MD\n",
    "        #     S1_FE_MN = S1_F_MN - S1_PRF_MN\n",
    "        #     err = gen_output(\n",
    "        #         S1_FE_MD, i, geopolygon, cell, aoi_m, \"flood_extents\", \"median\"\n",
    "        #     )\n",
    "        #     if len(err) > 0:\n",
    "        #         e_log.extend(err)\n",
    "        #     err = gen_output(\n",
    "        #         S1_FE_MN, i, geopolygon, cell, aoi_m, \"flood_extents\", \"mean\"\n",
    "        #     )\n",
    "        #     if len(err) > 0:\n",
    "        #         e_log.extend(err)\n",
    "\n",
    "        cell += 1\n",
    "        clear_output()\n",
    "\n",
    "    if len(e_log) == 0:\n",
    "        print(\n",
    "            \"\\n\\n\"\n",
    "            + \"\\033[32m\"\n",
    "            + \"GRID PROCESSED AND UPLOADED SUCCESSFULLY\"\n",
    "            + \"\\033[0m\"\n",
    "            + \"\\n\\n\"\n",
    "        )\n",
    "\n",
    "    # e_log = gen_elog(e_log)\n",
    "\n",
    "    # return e_log to be run again\n",
    "    return e_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crete the aoi-mosaic - aoi_m\n",
    "def gen_aoim(c: list, b: float) -> list:\n",
    "    \"\"\"\n",
    "    Generates the feature collection list (list of cells) using centroid coordinates and a buffer distance. Calls the main iterator for execution as well.\n",
    "\n",
    "    Parameters:\n",
    "    c: list, required\n",
    "        List of [x, y, cell_id and None]. None will store the error \"P\" - Processing or \"U\" - Upload, if executio fails.\n",
    "    b: float, required\n",
    "        Cell half-dimension in degrees (EPSG:4326). Creates a cell by adding this distance to the centroid coordinates.\n",
    "\n",
    "    Returns:\n",
    "    e_log: list\n",
    "        Error log list of [x, y, cell_id and None]. None will store the error \"P\" - Processing or \"U\" - Upload.\n",
    "    \"\"\"\n",
    "    aoi_m = []\n",
    "    for i in c:\n",
    "        aoi_m.append(define_area(i[1], i[0], buffer=b))\n",
    "    # print(c, len(aoi_m))\n",
    "    e_log = iterate_grid(aoi_m, c)\n",
    "\n",
    "    # return e_log to be run again\n",
    "    return e_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize input file\n",
    "def view_input(gdf_list: list[gpd.GeoDataFrame], grid_c: list) -> None:\n",
    "    \"\"\"\n",
    "    Visualizes cells and respective IDs  on a basemap.\n",
    "\n",
    "    Parameters:\n",
    "    gdf_list:list[gpd.GeoDataFrame], required\n",
    "        List of geodataframes to be visualized.\n",
    "    grid_c:list, required\n",
    "        List of [x, y, cell_id and None]. None will store the error \"P\" - Processing or \"U\" - Upload, if executio fails.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Visualizing data...\")\n",
    "    p = gdf_list[0].dissolve()\n",
    "    center = p.centroid\n",
    "    map = folium.Map(location=[center.y, center.x], tiles=\"CartoDB Positron\")\n",
    "\n",
    "    for gdf in gdf_list:\n",
    "        folium.GeoJson(gdf, name=\"{}\".format(gdf)).add_to(map)\n",
    "\n",
    "    for c in grid_c:\n",
    "        folium.Marker(\n",
    "            location=[c[1], c[0]],\n",
    "            popup=f\"Centroid: {c[1]}, {c[0]}\",\n",
    "            icon=folium.DivIcon(\n",
    "                icon_size=(10, 10),\n",
    "                icon_anchor=(0, 0),\n",
    "                html='<div style=\"font-size: 10pt\">{}</div>'.format(c[2]),\n",
    "            ),\n",
    "        ).add_to(map)\n",
    "\n",
    "    bounds = gdf_list[0].total_bounds.tolist()\n",
    "    map.fit_bounds([bounds[:2][::-1], bounds[2:][::-1]])\n",
    "    display(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid\n",
    "from shapely import intersection as intersect\n",
    "\n",
    "\n",
    "def create_grid(adm0: gpd.GeoDataFrame, size: float) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Divides adm0 AOI vectorfile into square grid based on size\n",
    "\n",
    "    Parameters:\n",
    "    adm0:gpd.GeoDataFrame, required\n",
    "        AMD0 GeoDataFrame created from ADM0 input vector file\n",
    "    size:float, required\n",
    "        Grid cell size in degrees (EPSG:4326)\n",
    "\n",
    "    Returns:\n",
    "    grid: gpd.GeoDataFrame\n",
    "        The generated grid GeoDataFrame\n",
    "    \"\"\"\n",
    "    bounds = adm0.bounds\n",
    "    minx = bounds.minx[0]  # only 1 feature at the 0th index\n",
    "    miny = bounds.miny[0]\n",
    "    maxx = bounds.maxx[0]\n",
    "    maxy = bounds.maxy[0]\n",
    "\n",
    "    grid = gpd.GeoDataFrame()\n",
    "    for x0 in np.arange(minx, maxx, size):\n",
    "        for y0 in np.arange(miny, maxy, size):\n",
    "            x1 = x0 + size\n",
    "            y1 = y0 + size\n",
    "            d = {\"geometry\": [Polygon([(x0, y0), (x1, y0), (x1, y1), (x0, y1)])]}\n",
    "            cell = gpd.GeoDataFrame(d, crs=\"EPSG:4326\")\n",
    "            flag = adm0.intersection(cell)\n",
    "            if flag[0].is_empty == False:\n",
    "                grid = pd.concat([grid, cell])\n",
    "\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CRS and convert to 4326 if required\n",
    "def crs_check(shp: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Checks input GeoDataFrame CRS and converts to EPSG 4326, if different.\n",
    "\n",
    "    Parameters:\n",
    "    shp: gpd.GeoDataFrame, required\n",
    "        Input GeoDataFrame to check.\n",
    "\n",
    "    Returns:\n",
    "    shp: gpd.GeoDataFrame\n",
    "        As is or converted GeoDataFrame.\n",
    "    \"\"\"\n",
    "    if shp.crs != \"EPSG:4326\":\n",
    "        print(\"Added ADM0 CRS is {}. Converting to EPSG:4326...\".format(shp.crs))\n",
    "        shp = shp.to_crs(\"EPSG:4326\")\n",
    "        if shp.crs == \"EPSG:4326\":\n",
    "            print(\"Done\")\n",
    "\n",
    "    return shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_inp(x: str) -> None:\n",
    "    \"\"\"\n",
    "    Checks if input is \"y\" or \"n\"\n",
    "\n",
    "    Parameters:\n",
    "    x: str, required\n",
    "        String input to be checked\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    if x not in [\"y\", \"n\"]:\n",
    "        raise ValueError(\"Invalid input, must be 'y' or 'n'\")\n",
    "    elif x == \"n\":\n",
    "        raise RuntimeError(\n",
    "            \"Excecution terminated. Make necessary changes before running again\"\n",
    "        )\n",
    "\n",
    "\n",
    "def exec_checks() -> None:\n",
    "    \"\"\"\n",
    "    Performs checks and Run the entire application\n",
    "\n",
    "    Parameters:\n",
    "    None\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    inst = \"\"\"\n",
    "Before running the execution, ensure all requirements have been met:\n",
    "1. Create appropriate folders in Google Drive and add their Folder IDs here\n",
    "2. Check input shapefile\n",
    "3. Check grid size\n",
    "    \n",
    "    \"\"\"\n",
    "    print(inst)\n",
    "\n",
    "    x = input(\"Folder IDs verified? (y/n):\")\n",
    "    check_inp(x)\n",
    "\n",
    "    x = input(\"Input shapefile/geojson verified? (y/n):\")\n",
    "    check_inp(x)\n",
    "\n",
    "    input(\"Grid (size) verified? (y/n):\")\n",
    "    check_inp(x)\n",
    "\n",
    "    z = input(\"\\nBegin execution for entire input shapefile/geojson? (y/n):\")\n",
    "    if z not in [\"y\", \"n\"]:\n",
    "        raise ValueError(\"Invalid input, must be 'y' or 'n'\")\n",
    "    elif z == \"n\":\n",
    "        raise RuntimeError(\n",
    "            \"Excecution terminated. Make necessary changes before running again\"\n",
    "        )\n",
    "    elif z == \"y\":\n",
    "        print(\"Starting execution...\")\n",
    "        # get e_log with centroids, cell_id and error message\n",
    "        # Calling gen_aoim will run the entire Application\n",
    "        e_log = gen_aoim(c, buffer)\n",
    "        print(len(e_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_files(path: str, ext: str) -> None:\n",
    "    \"\"\"\n",
    "    Deletes all files with specified extention at specified folder path\n",
    "\n",
    "    Parameters:\n",
    "    path:str, required\n",
    "        Folder path.\n",
    "    ext:str, required\n",
    "        File extension. \"*\" for all files.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    res_files = False\n",
    "    loc = os.path.join(path, ext)\n",
    "    files = glob.glob(loc)\n",
    "    if len(files) > 0:\n",
    "        res_files = True\n",
    "        print(\"Found {} files. Deleting...\".format(len(files)))\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "\n",
    "    return res_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dirs() -> None:\n",
    "    \"\"\"\n",
    "    Creates directories if they dont exist or deletes residual files if they exist.\n",
    "\n",
    "    Parameters:\n",
    "    None\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    dirs_exist = False\n",
    "    dir_dict = {\n",
    "        \"sd_flood\": \"output/flood\",\n",
    "        \"sd_preflood\": \"output/preflood\",\n",
    "        \"sd_flood_extents\": \"output/flood_extents\",\n",
    "    }\n",
    "\n",
    "    for k in dir_dict:\n",
    "        if not os.path.exists(dir_dict[k]):\n",
    "            os.makedirs(dir_dict[k])\n",
    "        else:\n",
    "            dirs_exist = True\n",
    "            r = del_files(dir_dict[k], \"*\")\n",
    "\n",
    "    if dirs_exist:\n",
    "        print(\"Output folders alredy exist.\")\n",
    "    else:\n",
    "        print(\"Output folders created.\")\n",
    "\n",
    "    if not r:\n",
    "        print(\"No residual files to delete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Gridded Vector File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folders alredy exist.\n",
      "No residual files to delete.\n",
      "Visualizing data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_453f04f805c590d683a8f4de2948260b {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_453f04f805c590d683a8f4de2948260b&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_453f04f805c590d683a8f4de2948260b = L.map(\n",
       "                &quot;map_453f04f805c590d683a8f4de2948260b&quot;,\n",
       "                {\n",
       "                    center: [13.450370788999997, 14.523475456],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 10,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_44eac470a1f042494bef482a031827fc = L.tileLayer(\n",
       "                &quot;https://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}{r}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors \\u0026copy; \\u003ca href=\\&quot;https://carto.com/attributions\\&quot;\\u003eCARTO\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 20, &quot;maxZoom&quot;: 20, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abcd&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_44eac470a1f042494bef482a031827fc.addTo(map_453f04f805c590d683a8f4de2948260b);\n",
       "        \n",
       "    \n",
       "\n",
       "        function geo_json_7d05c17eb83d862c55f54fa9e1ea075e_onEachFeature(feature, layer) {\n",
       "            layer.on({\n",
       "            });\n",
       "        };\n",
       "        var geo_json_7d05c17eb83d862c55f54fa9e1ea075e = L.geoJson(null, {\n",
       "                onEachFeature: geo_json_7d05c17eb83d862c55f54fa9e1ea075e_onEachFeature,\n",
       "            \n",
       "        });\n",
       "\n",
       "        function geo_json_7d05c17eb83d862c55f54fa9e1ea075e_add (data) {\n",
       "            geo_json_7d05c17eb83d862c55f54fa9e1ea075e\n",
       "                .addData(data);\n",
       "        }\n",
       "            geo_json_7d05c17eb83d862c55f54fa9e1ea075e_add({&quot;bbox&quot;: [14.273475456, 12.950370789, 14.773475456, 13.950370789], &quot;features&quot;: [{&quot;bbox&quot;: [14.273475456, 12.950370789, 14.523475456, 13.200370789], &quot;geometry&quot;: {&quot;coordinates&quot;: [[[14.273475456, 12.950370789], [14.523475456, 12.950370789], [14.523475456, 13.200370789], [14.273475456, 13.200370789], [14.273475456, 12.950370789]]], &quot;type&quot;: &quot;Polygon&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;properties&quot;: {}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [14.273475456, 13.200370789, 14.523475456, 13.450370789], &quot;geometry&quot;: {&quot;coordinates&quot;: [[[14.273475456, 13.200370789], [14.523475456, 13.200370789], [14.523475456, 13.450370789], [14.273475456, 13.450370789], [14.273475456, 13.200370789]]], &quot;type&quot;: &quot;Polygon&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;properties&quot;: {}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [14.273475456, 13.450370789, 14.523475456, 13.700370789], &quot;geometry&quot;: {&quot;coordinates&quot;: [[[14.273475456, 13.450370789], [14.523475456, 13.450370789], [14.523475456, 13.700370789], [14.273475456, 13.700370789], [14.273475456, 13.450370789]]], &quot;type&quot;: &quot;Polygon&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;properties&quot;: {}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [14.273475456, 13.700370789, 14.523475456, 13.950370789], &quot;geometry&quot;: {&quot;coordinates&quot;: [[[14.273475456, 13.700370789], [14.523475456, 13.700370789], [14.523475456, 13.950370789], [14.273475456, 13.950370789], [14.273475456, 13.700370789]]], &quot;type&quot;: &quot;Polygon&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;properties&quot;: {}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [14.523475456, 12.950370789, 14.773475456, 13.200370789], &quot;geometry&quot;: {&quot;coordinates&quot;: [[[14.523475456, 12.950370789], [14.773475456, 12.950370789], [14.773475456, 13.200370789], [14.523475456, 13.200370789], [14.523475456, 12.950370789]]], &quot;type&quot;: &quot;Polygon&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;properties&quot;: {}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [14.523475456, 13.200370789, 14.773475456, 13.450370789], &quot;geometry&quot;: {&quot;coordinates&quot;: [[[14.523475456, 13.200370789], [14.773475456, 13.200370789], [14.773475456, 13.450370789], [14.523475456, 13.450370789], [14.523475456, 13.200370789]]], &quot;type&quot;: &quot;Polygon&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;properties&quot;: {}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [14.523475456, 13.450370789, 14.773475456, 13.700370789], &quot;geometry&quot;: {&quot;coordinates&quot;: [[[14.523475456, 13.450370789], [14.773475456, 13.450370789], [14.773475456, 13.700370789], [14.523475456, 13.700370789], [14.523475456, 13.450370789]]], &quot;type&quot;: &quot;Polygon&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;properties&quot;: {}, &quot;type&quot;: &quot;Feature&quot;}, {&quot;bbox&quot;: [14.523475456, 13.700370789, 14.773475456, 13.950370789], &quot;geometry&quot;: {&quot;coordinates&quot;: [[[14.523475456, 13.700370789], [14.773475456, 13.700370789], [14.773475456, 13.950370789], [14.523475456, 13.950370789], [14.523475456, 13.700370789]]], &quot;type&quot;: &quot;Polygon&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;properties&quot;: {}, &quot;type&quot;: &quot;Feature&quot;}], &quot;type&quot;: &quot;FeatureCollection&quot;});\n",
       "        geo_json_7d05c17eb83d862c55f54fa9e1ea075e.setStyle(function(feature) {return feature.properties.style;});\n",
       "\n",
       "        \n",
       "    \n",
       "            geo_json_7d05c17eb83d862c55f54fa9e1ea075e.addTo(map_453f04f805c590d683a8f4de2948260b);\n",
       "        \n",
       "    \n",
       "\n",
       "        function geo_json_b84121349b19bb5d6d4ab39a141236b9_onEachFeature(feature, layer) {\n",
       "            layer.on({\n",
       "            });\n",
       "        };\n",
       "        var geo_json_b84121349b19bb5d6d4ab39a141236b9 = L.geoJson(null, {\n",
       "                onEachFeature: geo_json_b84121349b19bb5d6d4ab39a141236b9_onEachFeature,\n",
       "            \n",
       "        });\n",
       "\n",
       "        function geo_json_b84121349b19bb5d6d4ab39a141236b9_add (data) {\n",
       "            geo_json_b84121349b19bb5d6d4ab39a141236b9\n",
       "                .addData(data);\n",
       "        }\n",
       "            geo_json_b84121349b19bb5d6d4ab39a141236b9_add({&quot;bbox&quot;: [14.273475456, 12.950370789, 14.773475456, 13.850370789], &quot;features&quot;: [{&quot;bbox&quot;: [14.273475456, 12.950370789, 14.773475456, 13.850370789], &quot;geometry&quot;: {&quot;coordinates&quot;: [[[14.473475456, 12.950370789], [14.453872027934088, 12.95133384366556], [14.434457391596773, 12.954213732919355], [14.415418520549107, 12.958982721853559], [14.396938769526981, 12.965594882497744], [14.3791961086348, 12.97398653613033], [14.36236140939608, 12.98407686653949], [14.34659679916727, 12.995768698327453], [14.33205409976269, 13.008949432762691], [14.318873365327452, 13.023492132167272], [14.30718153353949, 13.03925674239608], [14.297091203130329, 13.0560914416348], [14.288699549497743, 13.073834102526982], [14.282087388853558, 13.092313853549108], [14.277318399919354, 13.111352724596774], [14.27443851066556, 13.130767360934088], [14.273475456, 13.150370789], [14.273475456, 13.650370789], [14.27443851066556, 13.669974217065912], [14.277318399919354, 13.689388853403226], [14.282087388853558, 13.708427724450893], [14.288699549497743, 13.726907475473018], [14.297091203130329, 13.7446501363652], [14.30718153353949, 13.76148483560392], [14.318873365327452, 13.777249445832728], [14.33205409976269, 13.79179214523731], [14.346596799167271, 13.804972879672547], [14.36236140939608, 13.81666471146051], [14.3791961086348, 13.82675504186967], [14.396938769526981, 13.835146695502257], [14.415418520549107, 13.841758856146441], [14.434457391596773, 13.846527845080645], [14.453872027934088, 13.84940773433444], [14.473475456, 13.850370789], [14.573475456, 13.850370789], [14.593078884065912, 13.84940773433444], [14.612493520403227, 13.846527845080645], [14.631532391450893, 13.841758856146441], [14.650012142473019, 13.835146695502257], [14.6677548033652, 13.82675504186967], [14.684589502603922, 13.81666471146051], [14.700354112832729, 13.804972879672547], [14.71489681223731, 13.79179214523731], [14.728077546672548, 13.777249445832728], [14.73976937846051, 13.76148483560392], [14.749859708869671, 13.7446501363652], [14.758251362502257, 13.726907475473018], [14.764863523146442, 13.708427724450893], [14.769632512080646, 13.689388853403226], [14.77251240133444, 13.669974217065912], [14.773475456, 13.650370789], [14.773475456, 13.150370789], [14.77251240133444, 13.130767360934088], [14.769632512080646, 13.111352724596774], [14.764863523146442, 13.092313853549108], [14.758251362502257, 13.073834102526982], [14.749859708869671, 13.0560914416348], [14.73976937846051, 13.03925674239608], [14.728077546672548, 13.023492132167272], [14.71489681223731, 13.008949432762691], [14.700354112832729, 12.995768698327453], [14.684589502603922, 12.98407686653949], [14.6677548033652, 12.97398653613033], [14.650012142473019, 12.965594882497744], [14.631532391450893, 12.958982721853559], [14.612493520403227, 12.954213732919355], [14.593078884065912, 12.95133384366556], [14.573475456, 12.950370789], [14.473475456, 12.950370789]]], &quot;type&quot;: &quot;Polygon&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;properties&quot;: {}, &quot;type&quot;: &quot;Feature&quot;}], &quot;type&quot;: &quot;FeatureCollection&quot;});\n",
       "        geo_json_b84121349b19bb5d6d4ab39a141236b9.setStyle(function(feature) {return feature.properties.style;});\n",
       "\n",
       "        \n",
       "    \n",
       "            geo_json_b84121349b19bb5d6d4ab39a141236b9.addTo(map_453f04f805c590d683a8f4de2948260b);\n",
       "        \n",
       "    \n",
       "            var marker_41b704823f6387ad982d70942619e326 = L.marker(\n",
       "                [13.07537, 14.39848],\n",
       "                {}\n",
       "            ).addTo(map_453f04f805c590d683a8f4de2948260b);\n",
       "        \n",
       "    \n",
       "            var div_icon_00cd080f89dfd701cf2e2472d969db82 = L.divIcon({&quot;className&quot;: &quot;empty&quot;, &quot;html&quot;: &quot;\\u003cdiv style=\\&quot;font-size: 10pt\\&quot;\\u003e1\\u003c/div\\u003e&quot;, &quot;iconAnchor&quot;: [0, 0], &quot;iconSize&quot;: [10, 10]});\n",
       "            marker_41b704823f6387ad982d70942619e326.setIcon(div_icon_00cd080f89dfd701cf2e2472d969db82);\n",
       "        \n",
       "    \n",
       "        var popup_28c15a5de6c996ece540538a2ee07cce = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_c21a0ca95c903f48326f35d6cc7800db = $(`&lt;div id=&quot;html_c21a0ca95c903f48326f35d6cc7800db&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Centroid: 13.07537, 14.39848&lt;/div&gt;`)[0];\n",
       "                popup_28c15a5de6c996ece540538a2ee07cce.setContent(html_c21a0ca95c903f48326f35d6cc7800db);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_41b704823f6387ad982d70942619e326.bindPopup(popup_28c15a5de6c996ece540538a2ee07cce)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_d58fabf5376560b2f9eadc096135f6c3 = L.marker(\n",
       "                [13.32537, 14.39848],\n",
       "                {}\n",
       "            ).addTo(map_453f04f805c590d683a8f4de2948260b);\n",
       "        \n",
       "    \n",
       "            var div_icon_275ccc2d824e412ab770533b2646fde2 = L.divIcon({&quot;className&quot;: &quot;empty&quot;, &quot;html&quot;: &quot;\\u003cdiv style=\\&quot;font-size: 10pt\\&quot;\\u003e2\\u003c/div\\u003e&quot;, &quot;iconAnchor&quot;: [0, 0], &quot;iconSize&quot;: [10, 10]});\n",
       "            marker_d58fabf5376560b2f9eadc096135f6c3.setIcon(div_icon_275ccc2d824e412ab770533b2646fde2);\n",
       "        \n",
       "    \n",
       "        var popup_9692cef298d9432a7e50b08ac5339f0c = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_40ad2394ce86f1961c79a0264968adf6 = $(`&lt;div id=&quot;html_40ad2394ce86f1961c79a0264968adf6&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Centroid: 13.32537, 14.39848&lt;/div&gt;`)[0];\n",
       "                popup_9692cef298d9432a7e50b08ac5339f0c.setContent(html_40ad2394ce86f1961c79a0264968adf6);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_d58fabf5376560b2f9eadc096135f6c3.bindPopup(popup_9692cef298d9432a7e50b08ac5339f0c)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_af8a3e77283ac0873fae1f96a709c76b = L.marker(\n",
       "                [13.57537, 14.39848],\n",
       "                {}\n",
       "            ).addTo(map_453f04f805c590d683a8f4de2948260b);\n",
       "        \n",
       "    \n",
       "            var div_icon_8e1c4718423444c865b6e635667fe2ff = L.divIcon({&quot;className&quot;: &quot;empty&quot;, &quot;html&quot;: &quot;\\u003cdiv style=\\&quot;font-size: 10pt\\&quot;\\u003e3\\u003c/div\\u003e&quot;, &quot;iconAnchor&quot;: [0, 0], &quot;iconSize&quot;: [10, 10]});\n",
       "            marker_af8a3e77283ac0873fae1f96a709c76b.setIcon(div_icon_8e1c4718423444c865b6e635667fe2ff);\n",
       "        \n",
       "    \n",
       "        var popup_d957c3a9db43e0cb3c4b937ea0f99548 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_20c4f238804350b2722f1671057024c2 = $(`&lt;div id=&quot;html_20c4f238804350b2722f1671057024c2&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Centroid: 13.57537, 14.39848&lt;/div&gt;`)[0];\n",
       "                popup_d957c3a9db43e0cb3c4b937ea0f99548.setContent(html_20c4f238804350b2722f1671057024c2);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_af8a3e77283ac0873fae1f96a709c76b.bindPopup(popup_d957c3a9db43e0cb3c4b937ea0f99548)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            map_453f04f805c590d683a8f4de2948260b.fitBounds(\n",
       "                [[12.950370789, 14.273475456], [13.950370789, 14.773475456]],\n",
       "                {}\n",
       "            );\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7f52ae16ba00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load file from sandbox disc. file should be present in 'input' folder\n",
    "# grid = gpd.read_file(\"input/Lake Chad.geojson\")\n",
    "# grid = gpd.read_file(\"input/TCD_55KM_4CTEST.geojson\")\n",
    "# grid = gpd.read_file(\"input/TCD_55KM_BASE.geojson\")\n",
    "# grid = gpd.read_file(\"input/TCD_55KM_ERR.geojson\")\n",
    "\n",
    "# Create and clean sandbox output directories\n",
    "clean_dirs()\n",
    "\n",
    "shp = \"input/Lake Chad.geojson\"\n",
    "# shp = \"input/TCD_55KM_BASE.geojson\"\n",
    "adm0_b = gpd.read_file(shp)  # adm0 base\n",
    "adm0_b = adm0_b.dissolve()\n",
    "adm0 = adm0_b.buffer(0.2)  # adm0 with 20KM boundary buffer\n",
    "adm0 = crs_check(adm0)\n",
    "size = 0.25  # Grid cell size 0.5 ~ 55KM\n",
    "buffer = size / 2  # cell buffer around the centroid to create the cell\n",
    "grid = create_grid(adm0, size)\n",
    "\n",
    "# Calculate centroids and store in centroid list c[].\n",
    "c = []\n",
    "g = grid.centroid\n",
    "\n",
    "cell_id = 1\n",
    "for i in g:\n",
    "    c.append(\n",
    "        [round(i.x, 5), round(i.y, 5), cell_id, None]\n",
    "    )  # The array c[] has four values: x, y, cell_id and None. None will store the \"P\" or \"U\" error value\n",
    "    cell_id += 1\n",
    "\n",
    "# Splice c to test with a few cells\n",
    "c = c[:3]  # 0-9 cells\n",
    "\n",
    "view_input([grid, adm0], c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and Run Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[32mGRID PROCESSED AND UPLOADED SUCCESSFULLY\u001b[0m\n",
      "\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Calls the checklist function\n",
    "exec_checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'e_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43me_log\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'e_log' is not defined"
     ]
    }
   ],
   "source": [
    "e_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Error Cells\n",
    "e_grid = gpd.GeoDataFrame()\n",
    "for e in e_log:\n",
    "    point = Point(e[0], e[1])  # This takes x first and then y\n",
    "    gdf = gpd.GeoDataFrame(geometry=[point])\n",
    "    buffer = 0.25\n",
    "    cell = gpd.GeoDataFrame()\n",
    "    cell[\"geometry\"] = gdf.buffer(buffer, cap_style=\"square\")\n",
    "    e_grid = pd.concat([e_grid, cell])\n",
    "e_grid = e_grid.set_crs(\"epsg:4326\")  # e_grid with same cell size as main grid\n",
    "\n",
    "# e_grid_aoi = e_grid.dissolve()\n",
    "# e_grid_fine = create_grid(e_grid_aoi, size) # if require to change the size and make it finer\n",
    "\n",
    "view_input([e_grid], e_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run application for cells logged in e_log\n",
    "if len(e_log) > 0:\n",
    "    e_log = gen_aoim(e_log, size / 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

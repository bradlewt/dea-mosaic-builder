{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIALIZE REQUIREMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import warnings \n",
    "import datacube\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as rio\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.ndimage.filters import uniform_filter\n",
    "from scipy.ndimage.measurements import variance\n",
    "from skimage.filters import threshold_minimum\n",
    "from datacube.utils.geometry import Geometry\n",
    "\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.plotting import display_map, rgb\n",
    "from deafrica_tools.areaofinterest import define_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "\n",
    "Connect to the datacube so we can access DEA data.\n",
    "The `app` parameter is a unique name for the analysis which is based on the notebook file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"Radar_water_detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUSTOMIZE DATA\n",
    "In the next three cells define the flood dates, threshold value and grid vector file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Flooding Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE PERIODS\n",
    "pre_flood = ['2024-04-15', '2024-05-15', '2024-06-15', '2023-07-15'] # 4 MONTHS PRIOR\n",
    "flood = ['2024-07-26', '2024-08-26', '2024-09-26', '2024-10-15'] # 4 MONTHS DURING\n",
    "# post_flood = ['2024-09-10', '2024-10-15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold_vh = -35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload file and calculate centroids\n",
    "\n",
    "Upload grid file with grid of ~10km x 10km or 0.1 degree. Here grid file of Lake Chad is used with 0.1 degree grid size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPLOAD FILE\n",
    "grid = gpd.read_file(\"input/Lake Chad.geojson\")\n",
    "\n",
    "# Calculate centroids and store in centroid list c[]. The array c[] will be used to loop all grid cells\n",
    "c = [] # INIT EMPTY GRID CENTROID\n",
    "g = grid.centroid # STORE ALL GRID CENTROIDS in g\n",
    "for i in g:\n",
    "    c.append([round(i.x, 5), round(i.y, 5)]) # EXTRACT x and y FROM POINT(x,y) AND APPEND TO c[]\n",
    "\n",
    "# AOI MOSAIC COVERING LAKE CHAD\n",
    "aoi_m = []\n",
    "for i in c:\n",
    "    aoi_m.append(define_area(i[1], i[0], buffer=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION DEFINITIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPECKLE FILTER FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function to apply lee filtering on S1 image \n",
    "def lee_filter(da, size):\n",
    "    \"\"\"\n",
    "    Apply lee filter of specified window size.\n",
    "    Adapted from https://stackoverflow.com/questions/39785970/speckle-lee-filter-in-python\n",
    "\n",
    "    \"\"\"\n",
    "    img = da.values\n",
    "    img_mean = uniform_filter(img, size)\n",
    "    img_sqr_mean = uniform_filter(img**2, size)\n",
    "    img_variance = img_sqr_mean - img_mean**2\n",
    "\n",
    "    overall_variance = variance(img)\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance)\n",
    "    img_output = img_mean + img_weights * (img - img_mean)\n",
    "    \n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFIER FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S1_water_classifier(da, threshold):\n",
    "    water_data_array = da < threshold\n",
    "    return water_data_array.to_dataset(name=\"s1_water\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main For Loop Interation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[32mPROCESSING GRID CELL 1/5\u001b[0m\n",
      "Using pixel quality parameters for Sentinel 1\n",
      "Finding datasets\n",
      "    s1_rtc\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 42 time steps\n",
      "-38.336662\n",
      "\n",
      "\n",
      "\u001b[32mPROCESSING GRID CELL 2/5\u001b[0m\n",
      "Using pixel quality parameters for Sentinel 1\n",
      "Finding datasets\n",
      "    s1_rtc\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 42 time steps\n",
      "-25.997452\n",
      "\n",
      "\n",
      "\u001b[32mPROCESSING GRID CELL 3/5\u001b[0m\n",
      "Using pixel quality parameters for Sentinel 1\n",
      "Finding datasets\n",
      "    s1_rtc\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 42 time steps\n",
      "-25.845648\n",
      "\n",
      "\n",
      "\u001b[32mPROCESSING GRID CELL 4/5\u001b[0m\n",
      "Using pixel quality parameters for Sentinel 1\n",
      "Finding datasets\n",
      "    s1_rtc\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 42 time steps\n",
      "-25.63038\n",
      "\n",
      "\n",
      "\u001b[32mPROCESSING GRID CELL 5/5\u001b[0m\n",
      "Using pixel quality parameters for Sentinel 1\n",
      "Finding datasets\n",
      "    s1_rtc\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 42 time steps\n",
      "-21.168266\n"
     ]
    }
   ],
   "source": [
    "grid_val = 1\n",
    "\n",
    "for aoi in aoi_m:\n",
    "    print(\"\\n\\n\"+ '\\033[32m' + \"PROCESSING GRID CELL {}/{}\".format(grid_val, len(aoi_m)) + '\\033[0m')\n",
    "    geopolygon = Geometry(aoi[\"features\"][0][\"geometry\"], crs=\"epsg:4326\")\n",
    "    geopolygon_gdf = gpd.GeoDataFrame(geometry=[geopolygon], crs=geopolygon.crs)\n",
    "\n",
    "    # Get the latitude and longitude range of the geopolygon\n",
    "    lat_range = (geopolygon_gdf.total_bounds[1], geopolygon_gdf.total_bounds[3])\n",
    "    lon_range = (geopolygon_gdf.total_bounds[0], geopolygon_gdf.total_bounds[2])\n",
    "\n",
    "    #timeframe\n",
    "    timerange = ('2024-01-01', '2024-10-01')\n",
    "\n",
    "    # LOAD SENTINEL-1 DATA\n",
    "    S1 = load_ard(dc=dc,\n",
    "                products=[\"s1_rtc\"],\n",
    "                measurements=['vv', 'vh'],\n",
    "                y=lat_range,\n",
    "                x=lon_range,\n",
    "                time=timerange,\n",
    "                output_crs = \"EPSG:6933\",\n",
    "                resolution = (-20,20),\n",
    "                group_by=\"solar_day\",\n",
    "                dtype='native'\n",
    "                )\n",
    "    \n",
    "    # INIT TIMESTEPS \n",
    "    timesteps = [2,4,6,9,11]\n",
    "\n",
    "    # VH/VV is a potentially useful third feature after VV and VH \n",
    "    S1['vh/vv'] = S1.vh/S1.vv  \n",
    "\n",
    "    # MEDIAN VALUES FOR SIMILAR RANGE FOR VISUALIZATION\n",
    "    med_s1 = S1[['vv','vh','vh/vv']].median()  \n",
    "\n",
    "    # The lee filter above doesn't handle null values\n",
    "    # We therefore set null values to 0 before applying the filter\n",
    "    valid = np.isfinite(S1)\n",
    "    S1 = S1.where(valid, 0)\n",
    "\n",
    "    # Create a new entry in dataset corresponding to filtered VV and VH data\n",
    "    S1[\"filtered_vv\"] = S1.vv.groupby(\"time\").apply(lee_filter, size=7)\n",
    "    S1[\"filtered_vh\"] = S1.vh.groupby(\"time\").apply(lee_filter, size=7)\n",
    "\n",
    "    # Null pixels should remain null\n",
    "    S1['filtered_vv'] = S1.filtered_vv.where(valid.vv)\n",
    "    S1['filtered_vh'] = S1.filtered_vh.where(valid.vh)   \n",
    "\n",
    "    # Convert the digital numbers to dB\n",
    "    S1['filtered_vv'] = 10 * np.log10(S1.filtered_vv)\n",
    "    S1['filtered_vh'] = 10 * np.log10(S1.filtered_vh)\n",
    "\n",
    "    threshold_vh = threshold_minimum(S1.filtered_vh.values)\n",
    "    print(threshold_vh)\n",
    "\n",
    "    S1['water'] = S1_water_classifier(S1.filtered_vh, threshold_vh).s1_water\n",
    "\n",
    "    # CREATE FLOODING OUTPUTS\n",
    "    S1['water_APR_JUL_24'] = S1.water.sel(time = pre_flood, method = 'nearest').mean(dim = 'time')\n",
    "    S1['water_JUL_OCT_24'] = S1.water.sel(time = flood, method = 'nearest').mean(dim = 'time')\n",
    "    # S1['water_SEP_OCT_24'] = S1.water.sel(time = post_flood, method = 'nearest').mean(dim = 'time')\n",
    "\n",
    "    # EXPORT TO RASTERS\n",
    "    out_ras_name = 'CELL_' + str(grid_val) + '_PRE_FLOOD.tif'\n",
    "    src_out = 'output/preflood/' + out_ras_name\n",
    "    S1.water_APR_JUL_24.rio.to_raster(src_out)\n",
    "\n",
    "    out_ras_name = 'CELL_' + str(grid_val) + '_FLOOD.tif'\n",
    "    src_out = 'output/flood/' + out_ras_name\n",
    "    S1.water_JUL_OCT_24.rio.to_raster(src_out)\n",
    "\n",
    "    # out_ras_name = 'CELL_' + str(grid_val) + '_POST_FLOOD_Mean.tif'\n",
    "    # src_out = 'output/postflood/' + out_ras_name\n",
    "    # S1.water_SEP_OCT_24.rio.to_raster(src_out)\n",
    "\n",
    "    grid_val += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Outputs To Disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['flood', 'preflood', 'postflood']\n",
    "\n",
    "for dir in dirs:\n",
    "    loc = \"output/\" + dir\n",
    "    out = \"output/{}/Merged_{}.tif\".format(dir, dir)\n",
    "    extension = \"*.tif\"\n",
    "    q = os.path.join(loc, extension)\n",
    "    files = glob.glob(q)\n",
    "\n",
    "    r =[]\n",
    "    for f in files:\n",
    "        s = rasterio.open(f)\n",
    "        r.append(s)\n",
    "    if len(r)>0:\n",
    "        mosaic, out_trans = merge(r)\n",
    "        out_meta = s.meta.copy()\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                    \"height\": mosaic.shape[1],\n",
    "                    \"width\": mosaic.shape[2],\n",
    "                    \"transform\": out_trans\n",
    "                    })\n",
    "        with rasterio.open(out, \"w\", **out_meta) as dest:\n",
    "            dest.write(mosaic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIALIZE REQUIREMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# !pip install python-dotenv\n",
    "# load_dotenv()\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "import os, glob, warnings, datacube, rasterio, folium, json\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as rio\n",
    "import pandas as pd\n",
    "from rasterio.merge import merge\n",
    "from rasterio.plot import show\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "\n",
    "from scipy.ndimage import uniform_filter\n",
    "from scipy.ndimage import variance\n",
    "from skimage.filters import threshold_minimum\n",
    "from datacube.utils.geometry import Geometry\n",
    "\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.plotting import display_map, rgb\n",
    "from deafrica_tools.areaofinterest import define_area\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local modules\n",
    "from tools.gdrive import GDrive\n",
    "gd = GDrive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Drive Storage\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loc</th>\n",
       "      <th>Size in GB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Capacity</td>\n",
       "      <td>2199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Available</td>\n",
       "      <td>2115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Usage</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drive Usage</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trash Usage</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Loc  Size in GB\n",
       "0     Capacity        2199\n",
       "1    Available        2115\n",
       "2        Usage          84\n",
       "3  Drive Usage          84\n",
       "4  Trash Usage           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "\n",
    "Connect to the datacube so we can access DEA data.\n",
    "The `app` parameter is a unique name for the analysis which is based on the notebook file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"Radar_water_detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G-Drive Folder IDs and Timerange Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder ids by copying the ID from the g-drive folder url\n",
    "FLOOD_MEAN_ID = \"196YsHy1SXjNDnja6LjVhhlvoIt-Jg91l\"\n",
    "FLOOD_MEDIAN_ID = \"1Qhum99pKi1Qyon8hcp4K8S_DGaJh5a5e\"\n",
    "\n",
    "PREFLOOD_MEAN_ID = \"1K0KqGlLxdUCsXg4771k_uf_x2UwbHlqa\"\n",
    "PREFLOOD_MEDIAN_ID = \"1Ovu5Q58xZRGpKsvowVr49klOrgVoZ0XQ\"\n",
    "\n",
    "FE_MEDIAN_ID = \"1CJfoCyWdcUo92nVyehWa2QQ-vshM9FTM\"\n",
    "\n",
    "ERR_FOLDER_ID = \"12ma2wfk79Vue8hgigPEu_QwGm_dWxqZE\"\n",
    "\n",
    "TEST1 = \"1jJu2W_HRTtOQ6qLl_uLjhgZrq82mIDpq\"\n",
    "TEST2 = \"1Os1331R3sCqwYyxVSOJUF9hq8zAszvdW\"\n",
    "TEST3 = \"1aNteouE_tQpJysLykoOjvCKN9Soh9oTC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRF_FOLDER_ID = TEST1\n",
    "F_FOLDER_ID = TEST2\n",
    "FE_FOLDER_ID = TEST3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main time period of analysis\n",
    "timerange = ('2024-02', '2024-09')\n",
    "\n",
    "# Define sub-periods of analysis - should be within main time period\n",
    "pre_flood = ['2024-02', '2024-03', '2024-04'] \n",
    "flood = ['2024-05', '2024-06', '2024-07', '2024-08', '2024-09'] \n",
    "\n",
    "# Run 1. aoi-threshold.ipynb to get the value of th_aoi and store it here.\n",
    "th_aoi = -27.395682"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter and Classifier Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply lee filtering on S1 image. Speckle Filter\n",
    "def lee_filter(da, size):\n",
    "    \"\"\"\n",
    "    Apply lee filter of specified window size.\n",
    "    Adapted from https://stackoverflow.com/questions/39785970/speckle-lee-filter-in-python\n",
    "\n",
    "    \"\"\"\n",
    "    img = da.values\n",
    "    img_mean = uniform_filter(img, size)\n",
    "    img_sqr_mean = uniform_filter(img**2, size)\n",
    "    img_variance = img_sqr_mean - img_mean**2\n",
    "\n",
    "    overall_variance = variance(img)\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance)\n",
    "    img_output = img_mean + img_weights * (img - img_mean)\n",
    "\n",
    "    return img_output\n",
    "\n",
    "# Classifier Function\n",
    "def S1_water_classifier(da, threshold):\n",
    "    water_data_array = da < threshold\n",
    "    return water_data_array.to_dataset(name=\"s1_water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Add mean and median generators as functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operational Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the input grid\n",
    "def iterate_grid(aoi_m, c):\n",
    "    \n",
    "    e_log = []\n",
    "    cell = 1\n",
    "    for aoi, i in zip(aoi_m, c):\n",
    "        geopolygon = Geometry(aoi[\"features\"][0][\"geometry\"], crs=\"epsg:4326\")\n",
    "        geopolygon_gdf = gpd.GeoDataFrame(geometry=[geopolygon], crs=geopolygon.crs)\n",
    "        g = geopolygon_gdf.centroid\n",
    "        print(\n",
    "            \"\\n\\n\"\n",
    "            + \"\\033[32m\"\n",
    "            + \"PROCESSING GRID CELL ID {} NO. {}/{} CENTROID ({}, {})\".format(\n",
    "                i[2], cell, len(aoi_m), round(g.y[0], 5), round(g.x[0], 5)\n",
    "            )\n",
    "            + \"\\033[0m\"\n",
    "        )\n",
    "    \n",
    "        # Get the latitude and longitude range of the geopolygon\n",
    "        lat_range = (geopolygon_gdf.total_bounds[1], geopolygon_gdf.total_bounds[3])\n",
    "        lon_range = (geopolygon_gdf.total_bounds[0], geopolygon_gdf.total_bounds[2])\n",
    "    \n",
    "        # Load Sentinel1 data\n",
    "        try:\n",
    "            S1 = load_ard(\n",
    "                dc=dc,\n",
    "                products=[\"s1_rtc\"],\n",
    "                # measurements=[\"vv\", \"vh\"],\n",
    "                measurements=[\"vh\"],\n",
    "                y=lat_range,\n",
    "                x=lon_range,\n",
    "                time=timerange,\n",
    "                output_crs=\"EPSG:6933\",\n",
    "                resolution=(-20, 20),\n",
    "                group_by=\"solar_day\",\n",
    "                dtype=\"native\",\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Log error aoi centroids and keep looping\n",
    "            e_log.append([g.x[0], g.y[0], i[2], \"P\"])\n",
    "            print(\n",
    "                \"\\n\\n\"\n",
    "                + \"\\033[31m\"\n",
    "                + \"ERROR PROCESSING GRID CELL {}/{} CENTROID ({}, {}). LOGGED CENTROID INFO in e_log\".format(\n",
    "                    i[2], len(aoi_m), round(g.y[0], 5), round(g.x[0], 5)\n",
    "                )\n",
    "                + \"\\033[0m\"\n",
    "            )\n",
    "            print(e)\n",
    "            cell += 1\n",
    "            continue\n",
    "    \n",
    "        # timesteps = [2, 4, 6, 9, 11]\n",
    "    \n",
    "        # The lee filter above doesn't handle null values\n",
    "        # We therefore set null values to 0 before applying the filter\n",
    "        valid = np.isfinite(S1)\n",
    "        S1 = S1.where(valid, 0)\n",
    "    \n",
    "        # Create a new entry in dataset corresponding to filtered VV and VH data\n",
    "        S1[\"filtered_vh\"] = S1.vh.groupby(\"time\").apply(lee_filter, size=7)\n",
    "    \n",
    "        # Null pixels should remain null\n",
    "        S1[\"filtered_vh\"] = S1.filtered_vh.where(valid.vh)\n",
    "    \n",
    "        # Convert the digital numbers to dB\n",
    "        S1[\"filtered_vh\"] = 10 * np.log10(S1.filtered_vh)\n",
    "    \n",
    "        threshold_vh = th_aoi\n",
    "    \n",
    "        S1[\"water\"] = S1_water_classifier(S1.filtered_vh, threshold_vh).s1_water\n",
    "        FS1 = S1.water\n",
    "        PRFS1 = S1.water\n",
    "    \n",
    "        # Creting outputs\n",
    "        # Export to raster - upload to g-drive - delete from sandbox\n",
    "        \n",
    "        # --------------------------------------- preflood ----------------------------------------------\n",
    "        if i[3] in [None, \"P\", \"U-PRF\"]:\n",
    "            S1_PreFlood = PRFS1.sel(time=pre_flood, method=\"nearest\").median(dim=\"time\")\n",
    "            preflood_val = \"CELL_\" + str(i[2]) + \"_PRE_FLOOD_MEDIAN\"\n",
    "            preflood_name = preflood_val + \".tif\"\n",
    "            preflood_out = \"output/preflood/\" + preflood_name\n",
    "            S1_PreFlood.rio.to_raster(preflood_out)\n",
    "            \n",
    "            # preflood meta\n",
    "            prf_meta_dict = {\n",
    "                \"GRID_CELL_ID\": i[2],\n",
    "                \"start_time\": pre_flood[0],\n",
    "                \"end_time\": pre_flood[-1],\n",
    "                \"lat\": lat_range, \n",
    "                \"lon\": lon_range,\n",
    "                \"centroid\": \"{}, {}\".format(g.y[0], g.x[0]),\n",
    "                \"crs\": str(geopolygon.crs)\n",
    "                }\n",
    "            \n",
    "            text_flie_name = preflood_val + \"_META.json\"\n",
    "            prf_meta_path = \"output/preflood/\" + text_flie_name\n",
    "            with open(prf_meta_path, 'w') as f:\n",
    "                json.dump(prf_meta_dict, f)\n",
    "            \n",
    "            try:\n",
    "                gd.upload_files([preflood_out, prf_meta_path], PRF_FOLDER_ID)\n",
    "            except Exception as e:\n",
    "                e_log.append([g.x[0], g.y[0], i[2], \"U-PRF\"])\n",
    "                print(\n",
    "                    \"\\n\\n\"\n",
    "                    + \"\\033[31m\"\n",
    "                    + \"ERROR UPLOADING GRID CELL ID {} NO.  {}/{} CENTROID ({}, {}). LOGGED CENTROID INFO in e_log\".format(\n",
    "                        cell, i[2], len(aoi_m), round(g.y[0], 5), round(g.x[0], 5)\n",
    "                    )\n",
    "                    + \"\\033[0m\"\n",
    "                )\n",
    "                print(e)\n",
    "                cell += 1\n",
    "    \n",
    "        # ----------------------------------------- flood ----------------------------------------------\n",
    "        if i[3] in [None, \"P\", \"U-F\"]:\n",
    "            S1_Flood = FS1.sel(time=flood, method=\"nearest\").median(dim=\"time\")\n",
    "            flood_val = \"CELL_\" + str(i[2]) + \"_FLOOD_MEDIAN\"\n",
    "            flood_name = flood_val + \".tif\"\n",
    "            flood_out = \"output/flood/\" + flood_name\n",
    "            S1_Flood.rio.to_raster(flood_out)\n",
    "            \n",
    "    \n",
    "            # flood meta\n",
    "            f_meta_dict = {\n",
    "                \"GRID_CELL_ID\": i[2],\n",
    "                \"start_time\": flood[0],\n",
    "                \"end_time\": flood[-1],\n",
    "                \"lat\": lat_range, \n",
    "                \"lon\": lon_range,\n",
    "                \"centroid\": \"{}, {}\".format(g.y[0], g.x[0]),\n",
    "                \"crs\": str(geopolygon.crs)\n",
    "                }\n",
    "            \n",
    "            text_flie_name = flood_val + \"_META.json\"\n",
    "            f_meta_path = \"output/flood/\" + text_flie_name\n",
    "            with open(f_meta_path, 'w') as f:\n",
    "                json.dump(f_meta_dict, f)\n",
    "            \n",
    "            try:\n",
    "                gd.upload_files([flood_out, f_meta_path], F_FOLDER_ID)\n",
    "            except Exception as e:\n",
    "                e_log.append([g.x[0], g.y[0], i[2], \"U-F\"])\n",
    "                print(\n",
    "                    \"\\n\\n\"\n",
    "                    + \"\\033[31m\"\n",
    "                    + \"ERROR UPLOADING GRID CELL ID {} NO. {}/{} CENTROID ({}, {}). LOGGED CENTROID INFO in e_log\".format(\n",
    "                        cell, i[2], len(aoi_m), round(g.y[0], 5), round(g.x[0], 5)\n",
    "                    )\n",
    "                    + \"\\033[0m\"\n",
    "                )\n",
    "                print(e)\n",
    "                cell += 1\n",
    "\n",
    "\n",
    "        # ----------------------------------------- difference ----------------------------------------------\n",
    "        if i[3] in [None, \"P\", \"U-FE\"]:\n",
    "            S1_FE = S1_Flood - S1_PreFlood\n",
    "            fe_val = \"CELL_\" + str(i[2]) + \"_FE_MEAN\"\n",
    "            fe_name = fe_val + \".tif\"\n",
    "            fe_out = \"output/fe/\" + fe_name\n",
    "            S1_FE.rio.to_raster(fe_out)\n",
    "            \n",
    "    \n",
    "            # flood meta\n",
    "            fe_meta_dict = {\n",
    "                \"GRID_CELL_ID\": i[2],\n",
    "                \"start_time\": timerange[0],\n",
    "                \"end_time\": timerange[-1],\n",
    "                \"lat\": lat_range, \n",
    "                \"lon\": lon_range,\n",
    "                \"centroid\": \"{}, {}\".format(g.y[0], g.x[0]),\n",
    "                \"crs\": str(geopolygon.crs)\n",
    "                }\n",
    "            \n",
    "            text_flie_name = fe_val + \"_META.json\"\n",
    "            fe_meta_path = \"output/fe/\" + text_flie_name\n",
    "            with open(fe_meta_path, 'w') as f:\n",
    "                json.dump(fe_meta_dict, f)\n",
    "            \n",
    "            try:\n",
    "                gd.upload_files([fe_out, fe_meta_path], FE_FOLDER_ID)\n",
    "            except Exception as e:\n",
    "                e_log.append([g.x[0], g.y[0], i[2], \"U-FE\"])\n",
    "                print(\n",
    "                    \"\\n\\n\"\n",
    "                    + \"\\033[31m\"\n",
    "                    + \"ERROR UPLOADING GRID CELL ID {} NO. {}/{} CENTROID ({}, {}). LOGGED CENTROID INFO in e_log\".format(\n",
    "                        cell, i[2], len(aoi_m), round(g.y[0], 5), round(g.x[0], 5)\n",
    "                    )\n",
    "                    + \"\\033[0m\"\n",
    "                )\n",
    "                print(e)\n",
    "                cell += 1\n",
    "\n",
    "        cell += 1\n",
    "        clear_output()\n",
    "    \n",
    "    if len(e_log) == 0:\n",
    "        print(\"\\n\\n\" + \"\\033[32m\" + \"GRID PROCESSED AND UPLOADED SUCCESSFULLY\" + \"\\033[0m\" + \"\\n\\n\")\n",
    "\n",
    "    # return e_log to be run again\n",
    "    return e_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crete the aoi-mosaic - aoi_m\n",
    "def gen_aoim(c, b):\n",
    "    aoi_m = []\n",
    "    for i in c:\n",
    "        aoi_m.append(define_area(i[1], i[0], buffer=b))\n",
    "    # print(c, len(aoi_m))\n",
    "    e_log = iterate_grid(aoi_m, c)\n",
    "\n",
    "    # return e_log to be run again\n",
    "    return e_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize input file\n",
    "def view_input(gdf_list, grid_c):\n",
    "    p = gdf_list[0].dissolve()\n",
    "    center = p.centroid\n",
    "    map = folium.Map(location=[center.y, center.x], tiles=\"CartoDB Positron\")\n",
    "    \n",
    "    for gdf in gdf_list:\n",
    "        folium.GeoJson(gdf, name=\"{}\".format(gdf)).add_to(map)\n",
    "\n",
    "    for c in grid_c:\n",
    "        folium.Marker(\n",
    "            location=[c[1], c[0]],\n",
    "            popup=f\"Centroid: {c[1]}, {c[0]}\",\n",
    "            icon= folium.DivIcon(\n",
    "                icon_size=(10, 10),\n",
    "                icon_anchor=(0,0),\n",
    "                html='<div style=\"font-size: 10pt\">{}</div>'.format(c[2]),\n",
    "                )\n",
    "        ).add_to(map)\n",
    "    \n",
    "    bounds = gdf_list[0].total_bounds.tolist()\n",
    "    map.fit_bounds([bounds[:2][::-1], bounds[2:][::-1]])\n",
    "    display(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid\n",
    "from shapely import intersection as intersect\n",
    "def create_grid(adm0, size):\n",
    "    bounds = adm0.bounds\n",
    "    minx = bounds.minx[0] #only 1 feature at the 0th index\n",
    "    miny = bounds.miny[0]\n",
    "    maxx = bounds.maxx[0]\n",
    "    maxy = bounds.maxy[0]\n",
    "\n",
    "    grid = gpd.GeoDataFrame()\n",
    "    for x0 in np.arange(minx, maxx, size):\n",
    "        for y0 in np.arange(miny, maxy, size):\n",
    "            x1 = x0 + size\n",
    "            y1 = y0 + size\n",
    "            d = {'geometry': [Polygon([(x0, y0), (x1, y0), (x1, y1), (x0, y1)])]}\n",
    "            cell = gpd.GeoDataFrame(d, crs=\"EPSG:4326\")\n",
    "            flag = adm0.intersection(cell)\n",
    "            if flag[0].is_empty == False:\n",
    "                grid = pd.concat([grid, cell])\n",
    "                \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CRS and convert to 4326 if required\n",
    "def crs_check(shp):\n",
    "    shp = gpd.read_file(shp)\n",
    "    if shp.crs != \"EPSG:4326\":\n",
    "        print(\"Added ADM0 CRS is {}. Converting to EPSG:4326...\".format(shp.crs))\n",
    "        shp = shp.to_crs(\"EPSG:4326\")\n",
    "        if shp.crs == \"EPSG:4326\":\n",
    "            print(\"Done\")\n",
    "\n",
    "    return shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Gridded Vector File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file from sandbox disc. file should be present in 'input' folder\n",
    "# grid = gpd.read_file(\"input/Lake Chad.geojson\")\n",
    "# grid = gpd.read_file(\"input/TCD_55KM_4CTEST.geojson\")\n",
    "# grid = gpd.read_file(\"input/TCD_55KM_BASE.geojson\")\n",
    "# grid = gpd.read_file(\"input/TCD_55KM_ERR.geojson\")\n",
    "\n",
    "shp = \"input/TCD_55KM_3857.geojson\"\n",
    "adm0 = crs_check(shp)\n",
    "size = 0.25  # Grid cell size 0.5 ~ 55KM\n",
    "buffer = size/2\n",
    "grid = create_grid(adm0, size)\n",
    "\n",
    "# Calculate centroids and store in centroid list c[].\n",
    "c = []\n",
    "g = grid.centroid\n",
    "\n",
    "cell_id = 1\n",
    "for i in g:\n",
    "    c.append(\n",
    "        [round(i.x, 5), round(i.y, 5), cell_id, None]\n",
    "    )  # The array c[] has four values: x, y, cell_id and None. None will store the \"P\" or \"U\" error value\n",
    "    cell_id += 1\n",
    "\n",
    "# # REMOVE THIS AFTER DONE\n",
    "# c = c[:10]\n",
    "view_input([grid, adm0], c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# get e_log with centroids, cell_id and error message\n",
    "# Calling gen_aoim will run the entire Application\n",
    "e_log = gen_aoim(c, buffer)\n",
    "\n",
    "print(len(e_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32merror_centroids.json UPLOADED SUCCESSFULLY\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[14.59848, 13.07537, 1, 'U-PRF']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write error log to disc\n",
    "e_log = np.array(e_log)\n",
    "with open('error_centroids.json', 'w') as filehandle:\n",
    "    json.dump(e_log.tolist(), filehandle)\n",
    "\n",
    "#read error log from disk\n",
    "with open('error_centroids.json') as f:\n",
    "    e_log = json.load(f)\n",
    "for e in e_log:\n",
    "    e[0] = float(e[0])\n",
    "    e[1] = float(e[1])\n",
    "    e[2] = int(e[2])\n",
    "\n",
    "try:\n",
    "    gd.upload_files([\"error_centroids.json\"], ERR_FOLDER_ID, False)\n",
    "except Exception as e:\n",
    "    print(\"FAILED TO UPLOAD ERROR LOG FILE REASON:{}\".format(e))\n",
    "\n",
    "e_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_678fe3ae8c8d4a9c08b308a10942397e {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_678fe3ae8c8d4a9c08b308a10942397e&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_678fe3ae8c8d4a9c08b308a10942397e = L.map(\n",
       "                &quot;map_678fe3ae8c8d4a9c08b308a10942397e&quot;,\n",
       "                {\n",
       "                    center: [13.07537, 14.59848],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 10,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_c55b84b1c2d88bd2bcad32587cffee0c = L.tileLayer(\n",
       "                &quot;https://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}{r}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors \\u0026copy; \\u003ca href=\\&quot;https://carto.com/attributions\\&quot;\\u003eCARTO\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 20, &quot;maxZoom&quot;: 20, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abcd&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_c55b84b1c2d88bd2bcad32587cffee0c.addTo(map_678fe3ae8c8d4a9c08b308a10942397e);\n",
       "        \n",
       "    \n",
       "\n",
       "        function geo_json_6a343d92d4aa7c0350fbbc2ff2b6c2d4_onEachFeature(feature, layer) {\n",
       "            layer.on({\n",
       "            });\n",
       "        };\n",
       "        var geo_json_6a343d92d4aa7c0350fbbc2ff2b6c2d4 = L.geoJson(null, {\n",
       "                onEachFeature: geo_json_6a343d92d4aa7c0350fbbc2ff2b6c2d4_onEachFeature,\n",
       "            \n",
       "        });\n",
       "\n",
       "        function geo_json_6a343d92d4aa7c0350fbbc2ff2b6c2d4_add (data) {\n",
       "            geo_json_6a343d92d4aa7c0350fbbc2ff2b6c2d4\n",
       "                .addData(data);\n",
       "        }\n",
       "            geo_json_6a343d92d4aa7c0350fbbc2ff2b6c2d4_add({&quot;bbox&quot;: [14.34848, 12.82537, 14.84848, 13.32537], &quot;features&quot;: [{&quot;bbox&quot;: [14.34848, 12.82537, 14.84848, 13.32537], &quot;geometry&quot;: {&quot;coordinates&quot;: [[[14.84848, 13.32537], [14.84848, 12.82537], [14.34848, 12.82537], [14.34848, 13.32537], [14.84848, 13.32537]]], &quot;type&quot;: &quot;Polygon&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;properties&quot;: {}, &quot;type&quot;: &quot;Feature&quot;}], &quot;type&quot;: &quot;FeatureCollection&quot;});\n",
       "        geo_json_6a343d92d4aa7c0350fbbc2ff2b6c2d4.setStyle(function(feature) {return feature.properties.style;});\n",
       "\n",
       "        \n",
       "    \n",
       "            geo_json_6a343d92d4aa7c0350fbbc2ff2b6c2d4.addTo(map_678fe3ae8c8d4a9c08b308a10942397e);\n",
       "        \n",
       "    \n",
       "            var marker_ac919fefb399f3f233cbc9c1dd15e800 = L.marker(\n",
       "                [13.07537, 14.59848],\n",
       "                {}\n",
       "            ).addTo(map_678fe3ae8c8d4a9c08b308a10942397e);\n",
       "        \n",
       "    \n",
       "            var div_icon_06c6ec80d12b8025d33c94843ab767a0 = L.divIcon({&quot;className&quot;: &quot;empty&quot;, &quot;html&quot;: &quot;\\u003cdiv style=\\&quot;font-size: 10pt\\&quot;\\u003e1\\u003c/div\\u003e&quot;, &quot;iconAnchor&quot;: [0, 0], &quot;iconSize&quot;: [10, 10]});\n",
       "            marker_ac919fefb399f3f233cbc9c1dd15e800.setIcon(div_icon_06c6ec80d12b8025d33c94843ab767a0);\n",
       "        \n",
       "    \n",
       "        var popup_0af942b490e69d5519c24c9e0a896b7b = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_77ae328e84e146cf92df355ab2563a6e = $(`&lt;div id=&quot;html_77ae328e84e146cf92df355ab2563a6e&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Centroid: 13.07537, 14.59848&lt;/div&gt;`)[0];\n",
       "                popup_0af942b490e69d5519c24c9e0a896b7b.setContent(html_77ae328e84e146cf92df355ab2563a6e);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_ac919fefb399f3f233cbc9c1dd15e800.bindPopup(popup_0af942b490e69d5519c24c9e0a896b7b)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            map_678fe3ae8c8d4a9c08b308a10942397e.fitBounds(\n",
       "                [[12.82537, 14.34848], [13.32537, 14.84848]],\n",
       "                {}\n",
       "            );\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7f8ee4224670>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize Error Cells\n",
    "e_grid = gpd.GeoDataFrame()\n",
    "for e in e_log:\n",
    "    point = Point(e[0], e[1]) #This takes x first and then y\n",
    "    gdf = gpd.GeoDataFrame(geometry=[point])\n",
    "    buffer = 0.25\n",
    "    cell = gpd.GeoDataFrame()\n",
    "    cell['geometry'] = gdf.buffer(buffer, cap_style='square')\n",
    "    e_grid = pd.concat([e_grid, cell])\n",
    "e_grid = e_grid.set_crs('epsg:4326') #e_grid with same cell size as main grid\n",
    "\n",
    "# e_grid_aoi = e_grid.dissolve()\n",
    "# e_grid_fine = create_grid(e_grid_aoi, size) # if require to change the size and make it finer\n",
    "\n",
    "view_input([e_grid], e_log)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[32mGRID PROCESSED AND UPLOADED SUCCESSFULLY\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-run application for cells logged in e_log\n",
    "if len(e_log)>0:\n",
    "    e_log = gen_aoim(e_log, size/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['flood', 'preflood', 'postflood']\n",
    "\n",
    "for dir in dirs:\n",
    "    loc = \"output/\" + dir\n",
    "    out = \"output/{}/Merged_{}.tif\".format(dir, dir)\n",
    "    extension = \"*.tif\"\n",
    "    q = os.path.join(loc, extension)\n",
    "    files = glob.glob(q)\n",
    "\n",
    "    r =[]\n",
    "    for f in files:\n",
    "        s = rasterio.open(f)\n",
    "        r.append(s)\n",
    "    if len(r)>0:\n",
    "        mosaic, out_trans = merge(r)\n",
    "        out_meta = s.meta.copy()\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                    \"height\": mosaic.shape[1],\n",
    "                    \"width\": mosaic.shape[2],\n",
    "                    \"transform\": out_trans\n",
    "                    })\n",
    "        with rasterio.open(out, \"w\", **out_meta) as dest:\n",
    "            dest.write(mosaic)\n",
    "            # gd.upload_files(out, \"flood\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
